{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment #0 - Data and Visualization\n",
    "\n",
    "<font color=\"red\"> <b> Due: Jan 31 (Friday) 11:00 pm </b> </font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"blue\"> Jerry Valentine </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. Introduction\n",
    "\n",
    "For this assignment I have found data sets for both regression and classification. The regression data is some traffic volume data that is used to predict what the volume of traffic on the road is based on features like weather and hour. The classification data is data from the 1994 Census. This data will be used to predict if a person is making more or less than 50k a year based on features like age, job, marrige status and so on. In this project the three main packages that are being used is numpy, pandas and matplotlib. numpy and pandas are used to clean up the data and present it as a table. matplotlib is used to represent the data as a scatter plot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II. Linear Algebra and Probability Theory\n",
    "\n",
    "## A. Linear Algebra\n",
    "Linear algebra is a very important topic for machine learning. Computers are extreamly efficienct when it comes to doing math with matrices. The basic building blocks of linear algebra are:[1]\n",
    "1. Scalars - A single number or constant.\n",
    "2. Vectors - A 1D array of numbers.\n",
    "3. Matrices - A 2D array of numbers.\n",
    "4. Tensors - An array of numbers of any dimention higher than 2D.\n",
    "\n",
    "An important operation is matrix multiplication. This is where you take two matrices of similar shape and combine them.\n",
    "\n",
    "Another important operation is transpose. This is where you flip a matrix on its size. This can be extreamly useful when needing to get two matrices shapes the same.\n",
    "\n",
    "\n",
    "## B. Probability Theory\n",
    "Probablity theory is also extreamly important for machine learning. Without probablity their wouldn't be machine learning. Probability theroy allows us to make very good predictions during uncertain moments. For AI systems, the laws of probability are used in two huge ways. Firstly, the laws of probability tell us how these systems should reason.[1] Secondly, probability is used to analyze the behavior of proposed systems.[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# III. Data\n",
    "\n",
    "## A. Regression\n",
    "\n",
    "For the regression data. I will be using Interstate Traffic Volume data, which can be found here: https://archive.ics.uci.edu/ml/datasets/Metro+Interstate+Traffic+Volume<br>\n",
    "\n",
    "A quick overview of what will be done with the data is: reading the csv file, checking for null values, converting strings to integers, getting rid of null values and useless data, seperating the input data from the output data, plotting those two arrays, taking the log of the output data and plotting the log output with the learning data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code cell is used to import the following packages:\n",
    "1. numpy - Used for its complex list manipulation and utility\n",
    "2. pandas - Used with numpy in order to add utilty to lists\n",
    "3. matplotlib - Used for plotting data\n",
    "4. datetime - Used for converting dates and times into ints.\n",
    "\n",
    "This code cell also reads in the Metro Interstate Traffic Volume data. The features of this data are:\n",
    "1. holiday - any holiday going on during that day.\n",
    "2. temp - The temprature of the hour in kelvin.\n",
    "3. rain_1h - the amount of rain in the hour in mm.\n",
    "4. snow_1h - the amount of snohw in the hour in mm.\n",
    "5. clouds_all - percentage of cloud coverage.\n",
    "6. weather_main - the weather in that hour.\n",
    "7. weather _description - a detailed description of the hours weather.\n",
    "8. date_time - the date and time of the data entry.\n",
    "9. traffic_volume - the volume of traffic on the highway."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "evalue": "Error: Jupyter cannot be started. Error attempting to locate jupyter: Error: Module 'notebook' not installed.",
     "output_type": "error"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "%matplotlib inline\n",
    "\n",
    "df = pd.read_csv(\"Metro_Interstate_Traffic_Volume.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code cell is checking if there is any obvious null values in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.any(df.isnull())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code cell is used to convert any non int values in the data into int values. The three columns that have non int data is holidy, weather_main and date_time. The mappings are as follows:<br>\n",
    "* holidy:\n",
    "  0. None\n",
    "  1. Columbus Day\n",
    "  2. Veterans Day\n",
    "  3. Thanksgiving Day\n",
    "  4. Christmas Day\n",
    "  5. New Years Day\n",
    "  6. Washingtons Birthday\n",
    "  7. Memorial Day\n",
    "  8. Independence Day\n",
    "  9. State Fair\n",
    "  10. Labor Day\n",
    "  11. Martin Luther King Jr Day\n",
    "* weather:\n",
    "  0. Clear\n",
    "  1. Clouds\n",
    "  2. Drizzle\n",
    "  3. Mist\n",
    "  4. Rain\n",
    "  5. Thunderstorm\n",
    "  6. Haze\n",
    "  7. Fog\n",
    "  8. Snow\n",
    "  9. Squall\n",
    "  10. Smoke\n",
    "* date_time: Continuous - converted into seconds past 1970"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "holidaydic = {'None': 0, 'Columbus Day': 1, 'Veterans Day': 2, 'Thanksgiving Day': 3, 'Christmas Day': 4, 'New Years Day': 5, 'Washingtons Birthday': 6, 'Memorial Day': 7, 'Independence Day': 8, 'State Fair': 9, 'Labor Day': 10, 'Martin Luther King Jr Day': 11}\n",
    "weatherdic = {'Clear': 0, 'Clouds': 1, 'Drizzle': 2, 'Mist': 3, 'Rain': 4, 'Thunderstorm': 5, 'Haze': 6, 'Fog': 7, 'Snow': 8, 'Squall': 9, 'Smoke': 10}\n",
    "\n",
    "df.holiday = df.holiday.apply(lambda s: holidaydic[s])\n",
    "df.weather_main = df.weather_main.apply(lambda s: weatherdic[s])\n",
    "df.date_time = df.date_time.apply(lambda s: datetime.timestamp(datetime.strptime(s, \"%Y-%m-%d %H:%M:%S\")))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next with this newly converted data, any values of 0 for temp are taken out and any date past Jun 11 2015 was taken out. The reason for the tempature being taken out was becuase temp was recorded in kelvin and 0 isn't possible for this data. The reason only data after Jun 11 2015 was kept was because there was a gap in the data of about a year.<br>\n",
    "\n",
    "The whole weather_description column was dropped becuase it wasn't something that would've been easily converted into ints and didn't seem helpful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.temp != 0] # Null values \n",
    "df = df[df.date_time > 1434063600] # Get rid of gap in time\n",
    "df = df.drop('weather_description', axis=1) # not great feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After removing all of the data I want to see the new shape of the list to make sure there is still enough data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step was to seperate the input data from the output data. The variable X represents the input data while the variable T represents output data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:, :-1].copy()\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = df.iloc[:, -1].copy()\n",
    "T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then this sepereated data is plotted. Each of the input columns are plotted on the x-axis on their own graph. The y-axis of each of these graphs is the output data.[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(16,12))\n",
    "plt.clf() # Clear previous plt figure\n",
    "for i in range(7):\n",
    "    plt.subplot(3, 4, i+1) # Selects which subplot to plot to\n",
    "    plt.scatter(X.iloc[:, i], T) # Plots a given column\n",
    "    plt.ylabel(\"Traffic Volume\") # Sets Y label\n",
    "    plt.xlabel(X.columns.values[i])\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From looking at the plots I have a hard time telling if any of these features correlate with traffic volumes. Some things that can be told though is there seems to be a lot less traffic during holidays. Another observation is when the weather is smoke there seems to be alot less traffic on the road but this could be due to not many data points with smoke. The final observation I made was when there is any snow at all traffic goes down albeit not always much does it always does."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next thing done to the data was taking the log of the output data. This was to look for any drastic changes from any of the data entries and to make the data less skewed. Then the data is replotted using the log of the output data with the same input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tlog = np.log(T + 1)\n",
    "D = pd.concat([X, T], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(16,12))\n",
    "plt.clf() # Clear previous plt figure\n",
    "for i in range(7):\n",
    "    plt.subplot(3, 4, i+1) # Selects which subplot to plot to\n",
    "    plt.scatter(X.iloc[:, i], T) # Plots a given column\n",
    "    plt.ylabel(\"Traffic Volume\") # Sets Y label\n",
    "    plt.xlabel(X.columns.values[i])\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final thing that was done was to take the log of the rain_1h feature. This feature was heavily skewed becuase of one data point. This looks like it might be the same with snow but it isn't because most of the data points aren't close to zero they are zero.[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.rain_1h = np.log(X.rain_1h + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(16,12))\n",
    "plt.clf() # Clear previous plt figure\n",
    "for i in range(7):\n",
    "    plt.subplot(3, 4, i+1) # Selects which subplot to plot to\n",
    "    plt.scatter(X.iloc[:, i], Tlog) # Plots a given column\n",
    "    plt.ylabel(\"Traffic Volume\") # Sets Y label\n",
    "    plt.xlabel(X.columns.values[i])\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preliminary Observation\n",
    "\n",
    "From looking at the plots using the output data logged, it doesn't seem there is anything that deters people from driving on the road. The feature that seems to have the biggest impact on traffic volume is rain per hour. After this feature is deskewed a little it does have a tiny impact on the amount of cars on the road."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification\n",
    "\n",
    "For the classification data. I will be using adult income data, which can be found here: https://archive.ics.uci.edu/ml/datasets/Census+Income\n",
    "\n",
    "A quick overview of what will be done with the data is: reading the csv file, checking for null values, getting rid of null values and useless data, converting strings to integers, seperating the input data from the output data, plotting those two lists as a scatter plot and plotting those two lists as a heat map.\n",
    "\n",
    "This code cell is used to import the following packages:\n",
    "\n",
    "1. numpy - Used for its complex list manipulation and utility\n",
    "2. pandas - Used with numpy in order to add utilty to lists\n",
    "3. matplotlib - Used for plotting data\n",
    "\n",
    "This code cell also reads in the adult census data. The features of this data are:\n",
    "1. age - The age of the person\n",
    "2. workclass - The class of work the person does\n",
    "3. fnlwgt - How many people are predicted to be in this situation\n",
    "4. education - The highest level of education for this person\n",
    "5. education-num - A numerical value for the education\n",
    "6. marital-status - If the person is married, single or divorced.\n",
    "7. occupation - The type of job the person works\n",
    "8. relationship - The relationship this person has to others like wife or husband\n",
    "9. race - The race of the person\n",
    "10. sex - The sex of the person\n",
    "11. capital-gain - The average gain in capital over a year.\n",
    "12. capital-loss The average loss in capital over a year.\n",
    "13. hours-per-week - The number of hours worked a week.\n",
    "14. native-country - The country the person was born in.\n",
    "15. class - If the person earns over 50k a year or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "%matplotlib inline\n",
    "\n",
    "df = pd.read_csv(\"adult.csv\", delimiter=\", \", names=['age', 'workclass', 'fnlwgt', 'education', 'educationnum', 'maritalstatus', 'occupation', 'relationship', 'race', 'sex', 'capitalgain', 'capitalloss', 'hoursperweek', 'nativecountry', 'incomeclass'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell is getting rid of any null values and checking to see if they are all gone. The educationnum feature is also dropped because I will convert the education column manualy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.workclass != '?']\n",
    "df = df[df.occupation != '?']\n",
    "df = df[df.nativecountry != '?']\n",
    "df = df.drop('educationnum', axis=1)\n",
    "\n",
    "np.any(df.isnull())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After removing all of that data I want to see the shape of the list to make sure there is still enough data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This next cell converts every feature that has strings into numbers.\n",
    "Here are all of the mappings\n",
    "* workclass\n",
    "  0. Private\n",
    "  1. Self-emp-not-inc\n",
    "  2. Self-emp-inc\n",
    "  3. Federal-gov\n",
    "  4. Local-gov\n",
    "  5. State-gov\n",
    "  6. Without-pay\n",
    "  7. Never-worked\n",
    "* education\n",
    "  0. Preschool\n",
    "  1. 1st-4th\n",
    "  2. 5th-6th\n",
    "  3. 7th-8th\n",
    "  4. 9th\n",
    "  5. 10th\n",
    "  6. 11th\n",
    "  7. 12th\n",
    "  8. HS-grad\n",
    "  9. Some-college\n",
    "  10. Assoc-voc\n",
    "  11. Assoc-acdm\n",
    "  12. Prof-school\n",
    "  13. Bachelors\n",
    "  14. Masters\n",
    "  15. Doctorate\n",
    "* maritalstatus\n",
    "  0. Married-civ-spouse\n",
    "  1. Divorced\n",
    "  2. Never-married\n",
    "  3. Separated\n",
    "  4. Widowed\n",
    "  5. Married-spouse-absent\n",
    "  6. Married-AF-spouse\n",
    "* ocupation\n",
    "  0. Tech-support\n",
    "  1. Craft-repair\n",
    "  2. Other-service\n",
    "  3. Sales\n",
    "  4. Exec-managerial\n",
    "  5. Prof-specialty\n",
    "  6. Handlers-cleaners\n",
    "  7. Machine-op-inspct\n",
    "  8. Adm-clerical\n",
    "  9. Farming-fishing\n",
    "  10. Transport-moving\n",
    "  11. Priv-house-serv\n",
    "  12. Protective-serv\n",
    "  13. Armed-Forces\n",
    "* relationship\n",
    "  0. Wife\n",
    "  1. Own-child\n",
    "  2. Husband\n",
    "  3. Not-in-family\n",
    "  4. Other-relative\n",
    "  5. Unmarried\n",
    "* race\n",
    "  0. White\n",
    "  1. Asian-Pac-Islander\n",
    "  2. Amer-Indian-Eskimo\n",
    "  3. Other\n",
    "  4. Black\n",
    "* sex\n",
    "  0. Female\n",
    "  1. Male\n",
    "* nativecountry\n",
    "  0. United-States\n",
    "  1. Cambodia\n",
    "  2. England\n",
    "  3. Puerto-Rico\n",
    "  4. Canada\n",
    "  5. Germany\n",
    "  6. Outlying-US(Guam-USVI-etc)\n",
    "  7. India\n",
    "  8. Japan\n",
    "  9. Greece\n",
    "  10. South\n",
    "  11. China\n",
    "  12. Cuba\n",
    "  13. Iran\n",
    "  14. Honduras\n",
    "  15. Philippines\n",
    "  16. Italy\n",
    "  17. Poland\n",
    "  18. Jamaica\n",
    "  19. Vietnam\n",
    "  20. Mexico\n",
    "  21. Portugal\n",
    "  22. Ireland\n",
    "  23. France\n",
    "  24. Dominican-Republic\n",
    "  25. Laos\n",
    "  26. Ecuador\n",
    "  27. Taiwan\n",
    "  28. Haiti\n",
    "  29. Columbia\n",
    "  30. Hungary\n",
    "  31. Guatemala\n",
    "  32. Nicaragua\n",
    "  33. Scotland\n",
    "  34. Thailand\n",
    "  35. Yugoslavia\n",
    "  36. El-Salvador\n",
    "  37. Trinadad&Tobago\n",
    "  38. Peru\n",
    "  39. Hong\n",
    "  40. Holand-Netherlands\n",
    "* incomeclass\n",
    "  0. \\>50k\n",
    "  1. <=50K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workclassdic = {'Private': 0, 'Self-emp-not-inc': 1, 'Self-emp-inc': 2, 'Federal-gov': 3, 'Local-gov': 4, 'State-gov': 5, 'Without-pay': 6, 'Never-worked': 7}\n",
    "educationdic = {'Preschool': 0, '1st-4th': 1, '5th-6th': 2, '7th-8th': 3, '9th': 4, '10th': 5, '11th': 6, '12th': 7, 'HS-grad': 8, 'Some-college': 9, 'Assoc-voc': 10, 'Assoc-acdm': 11, 'Prof-school': 12, 'Bachelors': 13, 'Masters': 14, 'Doctorate': 15}\n",
    "maritalstatusdic = {'Married-civ-spouse': 0, 'Divorced': 1, 'Never-married': 2, 'Separated': 3, 'Widowed': 4, 'Married-spouse-absent': 5, 'Married-AF-spouse': 6}\n",
    "occupationdic = {'Tech-support': 0, 'Craft-repair': 1, 'Other-service': 2, 'Sales': 3, 'Exec-managerial': 4, 'Prof-specialty': 5, 'Handlers-cleaners': 6, 'Machine-op-inspct': 7, 'Adm-clerical': 8, 'Farming-fishing': 9, 'Transport-moving': 10, 'Priv-house-serv': 11, 'Protective-serv': 12, 'Armed-Forces': 13}\n",
    "relationshipdic = {'Wife': 0, 'Own-child': 1, 'Husband': 2, 'Not-in-family': 3, 'Other-relative': 4, 'Unmarried': 5}\n",
    "racedic = {'White': 0, 'Asian-Pac-Islander': 1, 'Amer-Indian-Eskimo': 2, 'Other': 3, 'Black': 4}\n",
    "sexdic = {'Female': 0, 'Male': 1}\n",
    "nativecountrydic = {'United-States': 0, 'Cambodia': 1, 'England': 2, 'Puerto-Rico': 3, 'Canada': 4, 'Germany': 5, 'Outlying-US(Guam-USVI-etc)': 6, 'India': 7, 'Japan': 8, 'Greece': 9, 'South': 10, 'China': 11, 'Cuba': 12, 'Iran': 13, 'Honduras': 14, 'Philippines': 15, 'Italy': 16, 'Poland': 17, 'Jamaica': 18, 'Vietnam': 19, 'Mexico': 20, 'Portugal': 21, 'Ireland': 22, 'France': 23, 'Dominican-Republic': 24, 'Laos': 25, 'Ecuador': 26, 'Taiwan': 27, 'Haiti': 28, 'Columbia': 29, 'Hungary': 30, 'Guatemala': 31, 'Nicaragua': 32, 'Scotland': 33, 'Thailand': 34, 'Yugoslavia': 35, 'El-Salvador': 36, 'Trinadad&Tobago': 37, 'Peru': 38, 'Hong': 39, 'Holand-Netherlands': 40}\n",
    "incomeclassdic = {'>50K': 1, '<=50K': 0}\n",
    "\n",
    "df.workclass = df.workclass.apply(lambda s: workclassdic[s])\n",
    "df.education = df.education.apply(lambda s: educationdic[s])\n",
    "df.maritalstatus = df.maritalstatus.apply(lambda s: maritalstatusdic[s])\n",
    "df.occupation = df.occupation.apply(lambda s: occupationdic[s])\n",
    "df.relationship = df.relationship.apply(lambda s: relationshipdic[s])\n",
    "df.race = df.race.apply(lambda s: racedic[s])\n",
    "df.sex = df.sex.apply(lambda s: sexdic[s])\n",
    "df.nativecountry = df.nativecountry.apply(lambda s: nativecountrydic[s])\n",
    "df.incomeclass = df.incomeclass.apply(lambda s: incomeclassdic[s])\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These next two columns seperate the input data from the output data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:, :-1].copy()\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = df.iloc[:, -1].copy()\n",
    "T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then the input and output data is plotted with the output data on the y-axis.[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(32,13))\n",
    "plt.clf() # Clear previous plt figure\n",
    "for i in range(13):\n",
    "    plt.subplot(3, 5, i+1) # Selects which subplot to plot to\n",
    "    plt.scatter(X.iloc[:, i], T) # Plots a given column\n",
    "    plt.ylabel(\"Income Class\") # Sets Y label\n",
    "    plt.xlabel(X.columns.values[i])\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After plotting the classification data as a scatter plot I wasn't to happy with it. It was hard to tell how many were at any given point. I think using a heatmap is a lot better of a way to visualize this data.[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(32,13))\n",
    "plt.clf() # Clear previous plt figure\n",
    "for i in range(13):\n",
    "    plt.subplot(3, 5, i+1) # Selects which subplot to plot to\n",
    "    plt.hist2d(X.iloc[:, i], T, bins=25, normed=False, cmap='plasma')\n",
    "    plt.ylabel(\"Income Class\") # Sets Y label\n",
    "    plt.xlabel(X.columns.values[i])\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preliminary Observation\n",
    "\n",
    "From looking at the heat maps I can make a few observations. Very young people and very old people usally don't make over 50K a year. Mostly middle aged people. I think this makes sense becuase that is usally when you start to hit the peak of your career before you retire. Another observation I can make is any education higher than highschool has the best chance of making over 50K a year. The last observation I made was most people that make over 40K a year work 40 or more hours a week."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IV. Conclusions\n",
    "\n",
    "What I learned from this assignment is it takes a lot of time to shape the data in a way that is usefull for use. I had a big chalange picking a source of data. It was hard looking through them and figuring out what exactly each column meant and how they encoded it sometimes. It was also chalanging to find what was used to mark null values in the data. I definitely learned and got more comforatable with preprossesing data and representing it in graphs. In the end I think this assignment does a good job of teaching the steps of preprocessing the data and how to visualise that data in different ways to try and get preliminary observations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "[1] “Applied Math and Machine Learning Basics.” Deep Learning, by Ian Goodfellow et al., The MIT Press, 2017.<br>\n",
    "[2] \"1-Data Visualization.ipynb\", Minwoo Jake Lee, https://webpages.uncc.edu/mlee173/teach/itcs4156/progress.html<br>\n",
    "[3] \"matplotlib Heatmap\", matplotlib, \"https://riptutorial.com/matplotlib/example/17254/heatmap\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grading\n",
    "\n",
    "DO NOT forget to submit your data! Your notebook is supposed to run fine without any error. \n",
    "** You don't need to run any ML algorithm.** This assignment only asks reading, visualizing, and writing your observations from it as we did in the lab.\n",
    "\n",
    "** Note: this is a WRITING assignment. Proper writing is REQUIRED. Comments are not considered as writing. ** \n",
    "\n",
    "\n",
    "Points | | Description\n",
    "--|--|:--\n",
    "10 | Introduction  \n",
    "20 | Review | \n",
    "| 10 | linear algebra\n",
    "| 10 | probability theory\n",
    "60 | Data | \n",
    " | 5| Introduction of data for regression & source\n",
    " | 5| Reading the data \n",
    " | 5| Preprocessing of the data (if need) \n",
    " | 10| Visualization of the data \n",
    " | 5| Preliminary observation \n",
    " | 5| Introduction of data for Classification & source\n",
    " | 5| Reading the data \n",
    " | 5| Preprocessing of the data (if need)\n",
    " | 10| Visualization of the data \n",
    " | 5| Preliminary observation \n",
    "5 | Conclusions \n",
    "5 | References \n",
    "\n",
    "When you are dealing with preprocessed data, you can simply state it. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
